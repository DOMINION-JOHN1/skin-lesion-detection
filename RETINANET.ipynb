{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DOMINION-JOHN1/skin-lesion-detection/blob/main/RETINANET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nJKxaH7zwFBX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ad8c35-dd83-4b25-eb25-3a95a333d2d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/MyDrive/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Specify the directory path\n",
        "drive_mount_point = '/content/drive/MyDrive/'\n",
        "\n",
        "# Check if the directory exists, and create it if it doesn't\n",
        "if not os.path.exists(drive_mount_point):\n",
        "    os.makedirs(drive_mount_point)\n",
        "\n",
        "# Now, mount Google Drive to the specified directory\n",
        "from google.colab import drive\n",
        "drive.mount(drive_mount_point, force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4puadgvU0hi",
        "outputId": "af350626-ea62-4bb5-c6d1-b459fcc2985c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-ptjrz5xq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-ptjrz5xq\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit b7c7f4ba82192ff06f2bbb162b9f67b00ea55867\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.4.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.15.2)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black (from detectron2==0.6)\n",
            "  Downloading black-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.11.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=6147748 sha256=8e423f7a5e931e84d7e0447130780a725026908775f88edba338f1bf904ef500\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q02qmcam/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=a0d20ddaa802dbfbe87821bf19b2ab4b8c3c9cfffbf4d5f6776d59f93f4b1339\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=876b3663aaa42295016c93a6d3926cd34d945472d1cbcb6c7f6035c03788df95\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-24.4.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-2.8.2 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "# (add --user if you don't have permission)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv6ezqLaGjXg",
        "outputId": "ebea2e7d-9a5a-4af9-d493-0129fe818fb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yacs in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs) (6.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade yacs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VmocrFj86_wU"
      },
      "outputs": [],
      "source": [
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader, DatasetCatalog, MetadataCatalog\n",
        "import torch  # Import torch for checking CUDA availability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_NYXJfOVgsw8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "548afc10-7ec2-487a-e6ae-74c3ec2c622c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available: True\n",
            "Selected CUDA Device: MIG-c9b91a4a-7727-50b5-9df6-0bb0b9467e14\n",
            "Current CUDA Device: 0 - Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"MIG-c9b91a4a-7727-50b5-9df6-0bb0b9467e14\"\n",
        "#configure cuda to be very verbos\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "# Check CUDA availability and the selected device\n",
        "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
        "print(f\"Selected CUDA Device: {os.environ.get('CUDA_VISIBLE_DEVICES')}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Current CUDA Device: {torch.cuda.current_device()} - {torch.cuda.get_device_name()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m2Yi2wWA7D21"
      },
      "outputs": [],
      "source": [
        "# ----------------------- Dataset registration -----------------------\n",
        "def register_dataset(name, json_path, img_dir):\n",
        "    if name not in DatasetCatalog.list():\n",
        "        register_coco_instances(name, {}, json_path, img_dir)\n",
        "    else:\n",
        "        print(f\"Dataset {name} is already registered.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_vAQr0vsg58p"
      },
      "outputs": [],
      "source": [
        "# Debug: List all registered datasets to ensure correct registration\n",
        "def list_registered_datasets():\n",
        "    print(\"Registered datasets:\")\n",
        "    for dataset_name in DatasetCatalog.list():\n",
        "        print(f\"- {dataset_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jvvFFKfi9bal"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kBItU5cFpbeo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "liUgSIOpxc_y"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import uuid\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "def yolo_to_coco(image_dir, label_dir, output_path, dataset_type):\n",
        "    images = []\n",
        "    annotations = []\n",
        "    # Define category mappings\n",
        "    categories = [{'id': 0, 'name': 'unlabeled'}]  # Replace with your actual category names\n",
        "    annotation_id = 1\n",
        "\n",
        "    # Get all image files\n",
        "    image_files = glob(os.path.join(image_dir, '*.png'))\n",
        "    for image_file in tqdm(image_files, desc=\"Processing images\"):\n",
        "        # Generate a random UUID for the image ID (optional)\n",
        "        image_id = str(uuid.uuid4())\n",
        "        image_info = {\n",
        "            'file_name': os.path.basename(image_file),\n",
        "            'height': 640,\n",
        "            'width': 640,\n",
        "            'id': image_id  # Use the generated or original image ID\n",
        "        }\n",
        "\n",
        "        label_file = os.path.join(label_dir, os.path.basename(image_file).replace('.png', '.txt'))\n",
        "\n",
        "        # Skip images with missing label files\n",
        "        if not os.path.exists(label_file):\n",
        "            print(f\"Warning: Label file not found for image: {image_file}\")\n",
        "            continue  # Skip to the next image\n",
        "\n",
        "        # Process the image only if the label file exists\n",
        "        with open(label_file, 'r') as file:\n",
        "            # Check for missing image ID within the label file\n",
        "            lines = file.readlines()\n",
        "            if len(lines) == 0:  # Empty label file signifies missing image ID\n",
        "                print(f\"Warning: Label file {label_file} is empty. Skipping image.\")\n",
        "                continue\n",
        "\n",
        "            for line in lines:\n",
        "                class_id, x_center, y_center, width, height = [float(x) for x in line.split()]\n",
        "                # Convert from YOLO to absolute COCO format\n",
        "                x_min = (x_center - width / 2) * 640\n",
        "                y_min = (y_center - height / 2) * 640\n",
        "                x_max = (x_center + width / 2) * 640\n",
        "                y_max = (y_center + height / 2) * 640\n",
        "\n",
        "                # Calculate area of the bounding box\n",
        "                width_abs = x_max - x_min\n",
        "                height_abs = y_max - y_min\n",
        "                area = width_abs * height_abs\n",
        "\n",
        "                annotation = {\n",
        "                    'id': annotation_id,  # Use a unique annotation ID\n",
        "                    'image_id': image_id,  # Use the same image ID as the image info\n",
        "                    'category_id': int(class_id),\n",
        "                    'bbox': [x_min, y_min, width_abs, height_abs],  # COCO format bounding box\n",
        "                    'bbox_mode': BoxMode.XYXY_ABS,\n",
        "                    'area': area,  # Include area of the bounding box\n",
        "                    'iscrowd': 0\n",
        "                }\n",
        "                annotations.append(annotation)\n",
        "                annotation_id += 1\n",
        "\n",
        "        images.append(image_info)\n",
        "\n",
        "    coco_format = {\n",
        "        'images': images,\n",
        "        'annotations': annotations,\n",
        "        'categories': categories\n",
        "    }\n",
        "    with open(output_path, 'w') as output_file:\n",
        "        json.dump(coco_format, output_file)\n",
        "\n",
        "# Assuming you have your dataset prepared and the COCO JSON file generated\n",
        "# ... rest of your training code ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nPvzsoO19e3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0364572-c5df-482f-8fe4-d9c8b349c246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 7/7 [00:02<00:00,  2.96it/s]\n"
          ]
        }
      ],
      "source": [
        "yolo_to_coco(\"/content/drive/MyDrive/MyDrive/skin lesions/images/train\",'/content/drive/MyDrive/MyDrive/skin lesions/labels/train',  \"/content/drive/MyDrive/MyDrive/skin lesions/labels/train/annotations_train.json\",\"train\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "907DDGrI9gSv"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import uuid\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "def yolo_to_coco(image_dir, label_dir, output_path, dataset_type):\n",
        "    images = []\n",
        "    annotations = []\n",
        "    # Define category mappings\n",
        "    categories = [{'id': 0, 'name': 'unlabeled'}]  # Replace with your actual category names\n",
        "    annotation_id = 1\n",
        "\n",
        "    # Get all image files\n",
        "    image_files = glob(os.path.join(image_dir, '*.png'))\n",
        "    for image_file in tqdm(image_files, desc=\"Processing images\"):\n",
        "        # Generate a random UUID for the image ID (optional)\n",
        "        image_id = str(uuid.uuid4())\n",
        "        image_info = {\n",
        "            'file_name': os.path.basename(image_file),\n",
        "            'height': 640,\n",
        "            'width': 640,\n",
        "            'id': image_id  # Use the generated or original image ID\n",
        "        }\n",
        "\n",
        "        label_file = os.path.join(label_dir, os.path.basename(image_file).replace('.png', '.txt'))\n",
        "\n",
        "        # Skip images with missing label files\n",
        "        if not os.path.exists(label_file):\n",
        "            print(f\"Warning: Label file not found for image: {image_file}\")\n",
        "            continue  # Skip to the next image\n",
        "\n",
        "        # Process the image only if the label file exists\n",
        "        with open(label_file, 'r') as file:\n",
        "            # Check for missing image ID within the label file\n",
        "            lines = file.readlines()\n",
        "            if len(lines) == 0:  # Empty label file signifies missing image ID\n",
        "                print(f\"Warning: Label file {label_file} is empty. Skipping image.\")\n",
        "                continue\n",
        "\n",
        "            for line in lines:\n",
        "                class_id, x_center, y_center, width, height = [float(x) for x in line.split()]\n",
        "                # Convert from YOLO to absolute COCO format\n",
        "                x_min = (x_center - width / 2) * 640\n",
        "                y_min = (y_center - height / 2) * 640\n",
        "                x_max = (x_center + width / 2) * 640\n",
        "                y_max = (y_center + height / 2) * 640\n",
        "\n",
        "                # Calculate area of the bounding box\n",
        "                width_abs = x_max - x_min\n",
        "                height_abs = y_max - y_min\n",
        "                area = width_abs * height_abs\n",
        "\n",
        "                annotation = {\n",
        "                    'id': annotation_id,  # Use a unique annotation ID\n",
        "                    'image_id': image_id,  # Use the same image ID as the image info\n",
        "                    'category_id': int(class_id),\n",
        "                    'bbox': [x_min, y_min, width_abs, height_abs],  # COCO format bounding box\n",
        "                    'bbox_mode': BoxMode.XYXY_ABS,\n",
        "                    'area': area,  # Include area of the bounding box\n",
        "                    'iscrowd': 0\n",
        "                }\n",
        "                annotations.append(annotation)\n",
        "                annotation_id += 1\n",
        "\n",
        "        images.append(image_info)\n",
        "\n",
        "    coco_format = {\n",
        "        'images': images,\n",
        "        'annotations': annotations,\n",
        "        'categories': categories\n",
        "    }\n",
        "    with open(output_path, 'w') as output_file:\n",
        "        json.dump(coco_format, output_file)\n",
        "\n",
        "# Assuming you have your dataset prepared and the COCO JSON file generated\n",
        "# ... rest of your training code ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1oLdXDcq1Dq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3207ab14-2bf4-4eaa-9f3d-8db805ff4a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 5/5 [00:01<00:00,  2.92it/s]\n"
          ]
        }
      ],
      "source": [
        "yolo_to_coco(\"/content/drive/MyDrive/MyDrive/skin lesions/images/val\",'/content/drive/MyDrive/MyDrive/skin lesions/labels/val',  \"/content/drive/MyDrive/MyDrive/skin lesions/labels/val/annotations_val.json\",\"val\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGQTG7mvhCZf",
        "outputId": "32891860-6f5b-4aa1-921b-baebf3ee1792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registered datasets:\n",
            "- coco_2014_train\n",
            "- coco_2014_val\n",
            "- coco_2014_minival\n",
            "- coco_2014_valminusminival\n",
            "- coco_2017_train\n",
            "- coco_2017_val\n",
            "- coco_2017_test\n",
            "- coco_2017_test-dev\n",
            "- coco_2017_val_100\n",
            "- keypoints_coco_2014_train\n",
            "- keypoints_coco_2014_val\n",
            "- keypoints_coco_2014_minival\n",
            "- keypoints_coco_2014_valminusminival\n",
            "- keypoints_coco_2017_train\n",
            "- keypoints_coco_2017_val\n",
            "- keypoints_coco_2017_val_100\n",
            "- coco_2017_train_panoptic_separated\n",
            "- coco_2017_train_panoptic_stuffonly\n",
            "- coco_2017_train_panoptic\n",
            "- coco_2017_val_panoptic_separated\n",
            "- coco_2017_val_panoptic_stuffonly\n",
            "- coco_2017_val_panoptic\n",
            "- coco_2017_val_100_panoptic_separated\n",
            "- coco_2017_val_100_panoptic_stuffonly\n",
            "- coco_2017_val_100_panoptic\n",
            "- lvis_v1_train\n",
            "- lvis_v1_val\n",
            "- lvis_v1_test_dev\n",
            "- lvis_v1_test_challenge\n",
            "- lvis_v0.5_train\n",
            "- lvis_v0.5_val\n",
            "- lvis_v0.5_val_rand_100\n",
            "- lvis_v0.5_test\n",
            "- lvis_v0.5_train_cocofied\n",
            "- lvis_v0.5_val_cocofied\n",
            "- cityscapes_fine_instance_seg_train\n",
            "- cityscapes_fine_sem_seg_train\n",
            "- cityscapes_fine_instance_seg_val\n",
            "- cityscapes_fine_sem_seg_val\n",
            "- cityscapes_fine_instance_seg_test\n",
            "- cityscapes_fine_sem_seg_test\n",
            "- cityscapes_fine_panoptic_train\n",
            "- cityscapes_fine_panoptic_val\n",
            "- voc_2007_trainval\n",
            "- voc_2007_train\n",
            "- voc_2007_val\n",
            "- voc_2007_test\n",
            "- voc_2012_trainval\n",
            "- voc_2012_train\n",
            "- voc_2012_val\n",
            "- ade20k_sem_seg_train\n",
            "- ade20k_sem_seg_val\n",
            "- train\n",
            "- test\n"
          ]
        }
      ],
      "source": [
        "register_dataset(\"train\", \"/content/drive/MyDrive/MyDrive/skin lesions/labels/train/annotations_train.json\", \"/content/drive/MyDrive/MyDrive/skin lesions/images/train\")\n",
        "register_dataset(\"test\", \"/content/drive/MyDrive/MyDrive/skin lesions/labels/val/annotations_val.json\", \"/content/drive/MyDrive/MyDrive/skin lesions/images/val\")\n",
        "list_registered_datasets()  # Call to list registered datasets for debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8yAmytLHN17A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32bb7a9-97f0-4670-f0d1-96c5c4ec8f83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.config:Loading config /usr/local/lib/python3.10/dist-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
          ]
        }
      ],
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"train\",)\n",
        "cfg.DATASETS.TEST = (\"test\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = (640, )\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = 640\n",
        "cfg.INPUT.MIN_SIZE_TEST = 640\n",
        "cfg.INPUT.MAX_SIZE_TEST = 640\n",
        "cfg.SOLVER.IMS_PER_BATCH = 16\n",
        "cfg.SOLVER.BASE_LR = 0.0025\n",
        "cfg.SOLVER.MAX_ITER = 1000\n",
        "cfg.SOLVER.STEPS = [25, 50]\n",
        "cfg.SOLVER.WARMUP_ITERS = 10\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "cfg.MODEL.DEVICE = \"cuda\"\n",
        "cfg.SEED = 10000\n",
        "cfg.OUTPUT_DIR = './train1'\n",
        "cfg.OUTPUT_ENABLED = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "klaluMQ7-9BX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b3afb9-5859-4125-b35e-22756c1241dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 1\n",
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Debug: Print the number of classes and check device setup\n",
        "print(f\"Number of classes: {cfg.MODEL.ROI_HEADS.NUM_CLASSES}\")\n",
        "print(f\"Device: {cfg.MODEL.DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "thZp28NcHgiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6d82bd-4a44-4d76-d6f7-63289997e640"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[04/15 12:51:52 d2.engine.defaults]: Model:\n",
            "RetinaNet(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelP6P7(\n",
            "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    )\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (head): RetinaNetHead(\n",
            "    (cls_subnet): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU()\n",
            "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (5): ReLU()\n",
            "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (7): ReLU()\n",
            "    )\n",
            "    (bbox_subnet): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU()\n",
            "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (5): ReLU()\n",
            "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (7): ReLU()\n",
            "    )\n",
            "    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (anchor_generator): DefaultAnchorGenerator(\n",
            "    (cell_anchors): BufferList()\n",
            "  )\n",
            ")\n",
            "WARNING [04/15 12:51:52 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[04/15 12:51:52 d2.data.datasets.coco]: Loaded 7 images in COCO format from /content/drive/MyDrive/MyDrive/skin lesions/labels/train/annotations_train.json\n",
            "[04/15 12:51:52 d2.data.build]: Removed 0 images with no usable annotations. 7 images left.\n",
            "[04/15 12:51:52 d2.data.build]: Distribution of instances among all 1 categories:\n",
            "|  category  | #instances   |\n",
            "|:----------:|:-------------|\n",
            "| unlabeled  | 17           |\n",
            "|            |              |\n",
            "[04/15 12:51:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640,), max_size=640, sample_style='choice'), RandomFlip()]\n",
            "[04/15 12:51:52 d2.data.build]: Using training sampler TrainingSampler\n",
            "[04/15 12:51:52 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[04/15 12:51:52 d2.data.common]: Serializing 7 elements to byte tensors and concatenating them all ...\n",
            "[04/15 12:51:52 d2.data.common]: Serialized dataset takes 0.00 MiB\n",
            "[04/15 12:51:52 d2.data.build]: Making batched data loader with batch_size=16\n",
            "[04/15 12:51:52 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "R-50.pkl: 102MB [00:00, 154MB/s]                            \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[04/15 12:51:53 d2.checkpoint.c2_model_loading]: Renaming Caffe2 weights ......\n",
            "[04/15 12:51:53 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone.bottom_up - Total num: 54\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "backbone.fpn_lateral3.{bias, weight}\n",
            "backbone.fpn_lateral4.{bias, weight}\n",
            "backbone.fpn_lateral5.{bias, weight}\n",
            "backbone.fpn_output3.{bias, weight}\n",
            "backbone.fpn_output4.{bias, weight}\n",
            "backbone.fpn_output5.{bias, weight}\n",
            "backbone.top_block.p6.{bias, weight}\n",
            "backbone.top_block.p7.{bias, weight}\n",
            "head.bbox_pred.{bias, weight}\n",
            "head.bbox_subnet.0.{bias, weight}\n",
            "head.bbox_subnet.2.{bias, weight}\n",
            "head.bbox_subnet.4.{bias, weight}\n",
            "head.bbox_subnet.6.{bias, weight}\n",
            "head.cls_score.{bias, weight}\n",
            "head.cls_subnet.0.{bias, weight}\n",
            "head.cls_subnet.2.{bias, weight}\n",
            "head.cls_subnet.4.{bias, weight}\n",
            "head.cls_subnet.6.{bias, weight}\n",
            "WARNING:fvcore.common.checkpoint:The checkpoint state_dict contains keys that are not used by the model:\n",
            "  fc1000.{bias, weight}\n",
            "  stem.conv1.bias\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[04/15 12:51:53 d2.engine.train_loop]: Starting training from iteration 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04/15 12:52:41 d2.utils.events]:  eta: 0:28:58  iter: 19  total_loss: 2.687  loss_cls: 1.826  loss_box_reg: 0.8629    time: 1.9389  last_time: 1.9332  data_time: 0.3756  last_data_time: 0.4275   lr: 0.0025  max_mem: 10284M\n",
            "[04/15 12:53:22 d2.utils.events]:  eta: 0:28:41  iter: 39  total_loss: 1.366  loss_cls: 0.9391  loss_box_reg: 0.4269    time: 1.9116  last_time: 1.7852  data_time: 0.3038  last_data_time: 0.2503   lr: 0.00025  max_mem: 10284M\n",
            "[04/15 12:53:59 d2.utils.events]:  eta: 0:28:20  iter: 59  total_loss: 0.998  loss_cls: 0.6425  loss_box_reg: 0.375    time: 1.8932  last_time: 2.0955  data_time: 0.2770  last_data_time: 0.4023   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 12:54:37 d2.utils.events]:  eta: 0:28:00  iter: 79  total_loss: 0.9142  loss_cls: 0.5611  loss_box_reg: 0.3579    time: 1.8909  last_time: 1.9098  data_time: 0.2777  last_data_time: 0.2520   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 12:55:16 d2.utils.events]:  eta: 0:27:52  iter: 99  total_loss: 0.8785  loss_cls: 0.5337  loss_box_reg: 0.3448    time: 1.9008  last_time: 1.8975  data_time: 0.2921  last_data_time: 0.2469   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 12:55:55 d2.utils.events]:  eta: 0:27:29  iter: 119  total_loss: 0.8789  loss_cls: 0.527  loss_box_reg: 0.3521    time: 1.9093  last_time: 1.8664  data_time: 0.3009  last_data_time: 0.2516   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 12:56:34 d2.utils.events]:  eta: 0:26:55  iter: 139  total_loss: 0.8477  loss_cls: 0.5076  loss_box_reg: 0.3372    time: 1.9163  last_time: 1.8716  data_time: 0.3068  last_data_time: 0.2537   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 12:57:13 d2.utils.events]:  eta: 0:26:20  iter: 159  total_loss: 0.8278  loss_cls: 0.496  loss_box_reg: 0.3318    time: 1.9192  last_time: 1.8591  data_time: 0.2870  last_data_time: 0.2453   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 12:57:52 d2.utils.events]:  eta: 0:25:43  iter: 179  total_loss: 0.79  loss_cls: 0.4733  loss_box_reg: 0.3186    time: 1.9226  last_time: 1.8804  data_time: 0.3038  last_data_time: 0.2509   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 12:58:31 d2.utils.events]:  eta: 0:25:07  iter: 199  total_loss: 0.7888  loss_cls: 0.4735  loss_box_reg: 0.3198    time: 1.9254  last_time: 1.9023  data_time: 0.3010  last_data_time: 0.2669   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 12:59:09 d2.utils.events]:  eta: 0:24:30  iter: 219  total_loss: 0.7544  loss_cls: 0.4528  loss_box_reg: 0.3042    time: 1.9267  last_time: 1.8650  data_time: 0.2916  last_data_time: 0.2400   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 12:59:48 d2.utils.events]:  eta: 0:23:53  iter: 239  total_loss: 0.7639  loss_cls: 0.4538  loss_box_reg: 0.3128    time: 1.9288  last_time: 1.8711  data_time: 0.3004  last_data_time: 0.2355   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:00:27 d2.utils.events]:  eta: 0:23:16  iter: 259  total_loss: 0.7418  loss_cls: 0.444  loss_box_reg: 0.2978    time: 1.9294  last_time: 1.8659  data_time: 0.2865  last_data_time: 0.2474   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:01:06 d2.utils.events]:  eta: 0:22:38  iter: 279  total_loss: 0.7444  loss_cls: 0.4418  loss_box_reg: 0.2986    time: 1.9304  last_time: 1.8973  data_time: 0.2924  last_data_time: 0.2450   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:01:45 d2.utils.events]:  eta: 0:22:00  iter: 299  total_loss: 0.7354  loss_cls: 0.4385  loss_box_reg: 0.297    time: 1.9310  last_time: 1.8700  data_time: 0.2934  last_data_time: 0.2519   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:02:24 d2.utils.events]:  eta: 0:21:23  iter: 319  total_loss: 0.7174  loss_cls: 0.4313  loss_box_reg: 0.2862    time: 1.9319  last_time: 1.8825  data_time: 0.2976  last_data_time: 0.2509   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:03:03 d2.utils.events]:  eta: 0:20:46  iter: 339  total_loss: 0.7023  loss_cls: 0.4188  loss_box_reg: 0.2823    time: 1.9331  last_time: 1.9174  data_time: 0.3040  last_data_time: 0.2715   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:03:42 d2.utils.events]:  eta: 0:20:09  iter: 359  total_loss: 0.6967  loss_cls: 0.4175  loss_box_reg: 0.2798    time: 1.9342  last_time: 1.8720  data_time: 0.3031  last_data_time: 0.2530   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:04:21 d2.utils.events]:  eta: 0:19:31  iter: 379  total_loss: 0.6995  loss_cls: 0.4166  loss_box_reg: 0.2823    time: 1.9353  last_time: 1.8838  data_time: 0.3055  last_data_time: 0.2577   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:05:00 d2.utils.events]:  eta: 0:18:54  iter: 399  total_loss: 0.6789  loss_cls: 0.4078  loss_box_reg: 0.2713    time: 1.9364  last_time: 1.8725  data_time: 0.3096  last_data_time: 0.2584   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:05:39 d2.utils.events]:  eta: 0:18:16  iter: 419  total_loss: 0.6862  loss_cls: 0.4101  loss_box_reg: 0.2741    time: 1.9365  last_time: 1.8719  data_time: 0.3022  last_data_time: 0.2460   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:06:17 d2.utils.events]:  eta: 0:17:38  iter: 439  total_loss: 0.6723  loss_cls: 0.404  loss_box_reg: 0.2659    time: 1.9359  last_time: 1.8838  data_time: 0.2920  last_data_time: 0.2648   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:06:56 d2.utils.events]:  eta: 0:17:00  iter: 459  total_loss: 0.6602  loss_cls: 0.3957  loss_box_reg: 0.2645    time: 1.9357  last_time: 1.8762  data_time: 0.3064  last_data_time: 0.2585   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:07:35 d2.utils.events]:  eta: 0:16:22  iter: 479  total_loss: 0.66  loss_cls: 0.3965  loss_box_reg: 0.2654    time: 1.9355  last_time: 2.0995  data_time: 0.3039  last_data_time: 0.4832   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:08:13 d2.utils.events]:  eta: 0:15:43  iter: 499  total_loss: 0.6739  loss_cls: 0.4034  loss_box_reg: 0.2704    time: 1.9344  last_time: 2.1874  data_time: 0.2893  last_data_time: 0.4560   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:08:51 d2.utils.events]:  eta: 0:15:05  iter: 519  total_loss: 0.6451  loss_cls: 0.3885  loss_box_reg: 0.2568    time: 1.9338  last_time: 2.1993  data_time: 0.3002  last_data_time: 0.4804   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:09:29 d2.utils.events]:  eta: 0:14:27  iter: 539  total_loss: 0.6469  loss_cls: 0.3894  loss_box_reg: 0.2587    time: 1.9324  last_time: 1.8842  data_time: 0.2871  last_data_time: 0.2634   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:10:08 d2.utils.events]:  eta: 0:13:49  iter: 559  total_loss: 0.6477  loss_cls: 0.3884  loss_box_reg: 0.2594    time: 1.9320  last_time: 1.8832  data_time: 0.3045  last_data_time: 0.2467   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:10:46 d2.utils.events]:  eta: 0:13:11  iter: 579  total_loss: 0.6229  loss_cls: 0.3764  loss_box_reg: 0.2461    time: 1.9311  last_time: 1.8828  data_time: 0.2896  last_data_time: 0.2642   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:11:24 d2.utils.events]:  eta: 0:12:33  iter: 599  total_loss: 0.6339  loss_cls: 0.3812  loss_box_reg: 0.251    time: 1.9309  last_time: 1.8378  data_time: 0.3034  last_data_time: 0.2460   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:12:02 d2.utils.events]:  eta: 0:11:55  iter: 619  total_loss: 0.6354  loss_cls: 0.3846  loss_box_reg: 0.2507    time: 1.9301  last_time: 1.8497  data_time: 0.2885  last_data_time: 0.2479   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:12:41 d2.utils.events]:  eta: 0:11:18  iter: 639  total_loss: 0.6315  loss_cls: 0.381  loss_box_reg: 0.2505    time: 1.9297  last_time: 1.8613  data_time: 0.3071  last_data_time: 0.2621   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:13:19 d2.utils.events]:  eta: 0:10:40  iter: 659  total_loss: 0.6242  loss_cls: 0.3785  loss_box_reg: 0.2442    time: 1.9293  last_time: 1.8476  data_time: 0.2958  last_data_time: 0.2659   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:13:57 d2.utils.events]:  eta: 0:10:02  iter: 679  total_loss: 0.6076  loss_cls: 0.369  loss_box_reg: 0.2389    time: 1.9288  last_time: 1.8344  data_time: 0.2955  last_data_time: 0.2492   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:14:36 d2.utils.events]:  eta: 0:09:24  iter: 699  total_loss: 0.6177  loss_cls: 0.3743  loss_box_reg: 0.2434    time: 1.9286  last_time: 1.8306  data_time: 0.3043  last_data_time: 0.2430   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:15:14 d2.utils.events]:  eta: 0:08:47  iter: 719  total_loss: 0.6091  loss_cls: 0.3699  loss_box_reg: 0.2392    time: 1.9280  last_time: 1.8627  data_time: 0.2902  last_data_time: 0.2655   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:15:53 d2.utils.events]:  eta: 0:08:09  iter: 739  total_loss: 0.6025  loss_cls: 0.3675  loss_box_reg: 0.2354    time: 1.9282  last_time: 1.8694  data_time: 0.3143  last_data_time: 0.2748   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:16:31 d2.utils.events]:  eta: 0:07:31  iter: 759  total_loss: 0.5898  loss_cls: 0.3614  loss_box_reg: 0.231    time: 1.9275  last_time: 1.8812  data_time: 0.2840  last_data_time: 0.2674   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:17:09 d2.utils.events]:  eta: 0:06:53  iter: 779  total_loss: 0.5891  loss_cls: 0.36  loss_box_reg: 0.2291    time: 1.9274  last_time: 1.8356  data_time: 0.3061  last_data_time: 0.2442   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:17:48 d2.utils.events]:  eta: 0:06:16  iter: 799  total_loss: 0.5747  loss_cls: 0.3525  loss_box_reg: 0.223    time: 1.9273  last_time: 2.1215  data_time: 0.3007  last_data_time: 0.4766   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:18:26 d2.utils.events]:  eta: 0:05:38  iter: 819  total_loss: 0.6054  loss_cls: 0.3676  loss_box_reg: 0.2376    time: 1.9268  last_time: 2.1722  data_time: 0.2874  last_data_time: 0.4503   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:19:04 d2.utils.events]:  eta: 0:05:00  iter: 839  total_loss: 0.5775  loss_cls: 0.3534  loss_box_reg: 0.2246    time: 1.9267  last_time: 2.0693  data_time: 0.3053  last_data_time: 0.4456   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:19:43 d2.utils.events]:  eta: 0:04:23  iter: 859  total_loss: 0.58  loss_cls: 0.3563  loss_box_reg: 0.2238    time: 1.9264  last_time: 2.1481  data_time: 0.2953  last_data_time: 0.4635   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:20:21 d2.utils.events]:  eta: 0:03:45  iter: 879  total_loss: 0.5843  loss_cls: 0.3603  loss_box_reg: 0.224    time: 1.9260  last_time: 1.8614  data_time: 0.2964  last_data_time: 0.2532   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:20:59 d2.utils.events]:  eta: 0:03:07  iter: 899  total_loss: 0.5745  loss_cls: 0.3559  loss_box_reg: 0.2187    time: 1.9259  last_time: 1.8723  data_time: 0.2999  last_data_time: 0.2567   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:21:38 d2.utils.events]:  eta: 0:02:30  iter: 919  total_loss: 0.5619  loss_cls: 0.3469  loss_box_reg: 0.213    time: 1.9256  last_time: 1.8363  data_time: 0.2945  last_data_time: 0.2510   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:22:16 d2.utils.events]:  eta: 0:01:52  iter: 939  total_loss: 0.5616  loss_cls: 0.3492  loss_box_reg: 0.2124    time: 1.9256  last_time: 1.8621  data_time: 0.3079  last_data_time: 0.2781   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:22:54 d2.utils.events]:  eta: 0:01:15  iter: 959  total_loss: 0.5666  loss_cls: 0.3519  loss_box_reg: 0.2147    time: 1.9252  last_time: 1.8411  data_time: 0.2902  last_data_time: 0.2452   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:23:33 d2.utils.events]:  eta: 0:00:37  iter: 979  total_loss: 0.5552  loss_cls: 0.3442  loss_box_reg: 0.2096    time: 1.9252  last_time: 1.8693  data_time: 0.3089  last_data_time: 0.2580   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:24:12 d2.utils.events]:  eta: 0:00:00  iter: 999  total_loss: 0.5405  loss_cls: 0.343  loss_box_reg: 0.2004    time: 1.9250  last_time: 1.8345  data_time: 0.3005  last_data_time: 0.2445   lr: 2.5e-05  max_mem: 10284M\n",
            "[04/15 13:24:12 d2.engine.hooks]: Overall training speed: 998 iterations in 0:32:01 (1.9250 s / it)\n",
            "[04/15 13:24:12 d2.engine.hooks]: Total training time: 0:32:06 (0:00:04 on hooks)\n",
            "WARNING [04/15 13:24:12 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[04/15 13:24:12 d2.data.datasets.coco]: Loaded 5 images in COCO format from /content/drive/MyDrive/MyDrive/skin lesions/labels/val/annotations_val.json\n",
            "[04/15 13:24:12 d2.data.build]: Distribution of instances among all 1 categories:\n",
            "|  category  | #instances   |\n",
            "|:----------:|:-------------|\n",
            "| unlabeled  | 6            |\n",
            "|            |              |\n",
            "[04/15 13:24:12 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]\n",
            "[04/15 13:24:12 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[04/15 13:24:12 d2.data.common]: Serializing 5 elements to byte tensors and concatenating them all ...\n",
            "[04/15 13:24:12 d2.data.common]: Serialized dataset takes 0.00 MiB\n",
            "WARNING [04/15 13:24:12 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
          ]
        }
      ],
      "source": [
        "# ----------------------- Training -----------------------\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YLg2jkd9Hg5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67d566b-e19f-4c5a-cfea-6761fc70ff4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING [04/15 13:24:12 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[04/15 13:24:12 d2.data.datasets.coco]: Loaded 5 images in COCO format from /content/drive/MyDrive/MyDrive/skin lesions/labels/val/annotations_val.json\n",
            "[04/15 13:24:12 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]\n",
            "[04/15 13:24:13 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[04/15 13:24:13 d2.data.common]: Serializing 5 elements to byte tensors and concatenating them all ...\n",
            "[04/15 13:24:13 d2.data.common]: Serialized dataset takes 0.00 MiB\n",
            "[04/15 13:24:13 d2.evaluation.evaluator]: Start inference on 5 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04/15 13:24:14 d2.evaluation.evaluator]: Total inference time: 0:00:00.112872 (0.112872 s / iter per device, on 1 devices)\n",
            "[04/15 13:24:14 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:00 (0.072730 s / iter per device, on 1 devices)\n",
            "[04/15 13:24:14 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[04/15 13:24:14 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[04/15 13:24:14 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[04/15 13:24:14 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.01 seconds.\n",
            "[04/15 13:24:14 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[04/15 13:24:14 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.013\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.117\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "[04/15 13:24:14 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.383 | 1.318  | 0.000  | 0.168 | 0.820 |  nan  |\n",
            "[04/15 13:24:14 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 0.38309968223099683,\n",
              "               'AP50': 1.3179717971797178,\n",
              "               'AP75': 0.0,\n",
              "               'APs': 0.16771064861588197,\n",
              "               'APm': 0.8201356670461174,\n",
              "               'APl': nan})])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# ----------------------- Evaluation -----------------------\n",
        "evaluator = COCOEvaluator(\"test\")\n",
        "val_loader = build_detection_test_loader(cfg, \"test\")\n",
        "inference_on_dataset(trainer.model, val_loader, evaluator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FRZJ7fGEpt7I"
      },
      "execution_count": 16,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}